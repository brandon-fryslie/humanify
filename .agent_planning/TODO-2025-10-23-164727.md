# TODO: Critical Bug Fixes
**Generated:** 2025-10-23 16:47:27
**Updated:** 2025-10-23 (Added functional tests)
**Source Plan:** PLAN-2025-10-23-164727.md
**Source STATUS:** STATUS-2025-10-23-164430.md

---

## Immediate Action Items (P0 - CRITICAL)

### 1. Fix Bug #1: Missing Optional Chaining in progress.ts
**File:** `/Users/bmf/Library/Mobile Documents/com~apple~CloudDocs/_mine/icode/brandon-fryslie_humanify/src/progress.ts`
**Line:** 29
**Priority:** P0 - CRITICAL
**Effort:** 1 minute
**Status:** ❌ NOT STARTED
**Tests:** ✅ CREATED (src/progress.test.ts validates fix)

**Current Code:**
```typescript
process.stdout.cursorTo(0);
```

**Fixed Code:**
```typescript
process.stdout.cursorTo?.(0);
```

**Why:** When stdout is redirected (piped to `tee` or file), `cursorTo` method doesn't exist. This crashes 100% of benchmark runs in normal mode.

**Validation:**
- Functional test created: `src/progress.test.ts`
- Test currently FAILS (detecting bug)
- Test will PASS after fix applied
- Run: `tsx --test src/progress.test.ts`

**Acceptance Criteria:**
- [ ] Add `?` operator after `cursorTo`
- [ ] Line 28 and 29 now consistent (both use optional chaining)
- [ ] No TypeScript errors after change
- [ ] Test `src/progress.test.ts` passes (4/4 tests)

---

### 2. Fix Bug #2: Missing Await in visit-all-identifiers.ts
**File:** `/Users/bmf/Library/Mobile Documents/com~apple~CloudDocs/_mine/icode/brandon-fryslie_humanify/src/plugins/local-llm-rename/visit-all-identifiers.ts`
**Lines:** 139-144
**Priority:** P0 - CRITICAL
**Effort:** 5 minutes
**Status:** ❌ NOT STARTED
**Tests:** ✅ CREATED (src/plugins/openai/openai-turbo.test.ts validates fix)

**Current Code:**
```typescript
// Extract contexts at current AST state (before parallel API calls)
const jobs = toProcess.map((scope) => ({
  scope,
  name: scope.node.name,
  context: scopeToString(scope, contextWindowSize)  // ❌ Returns Promise, not string
}));
```

**Fixed Code (Recommended - Maintains Parallelization):**
```typescript
// Extract all contexts in parallel
const contexts = await Promise.all(
  toProcess.map(scope => scopeToString(scope, contextWindowSize))
);

// Build jobs with resolved contexts
const jobs = toProcess.map((scope, i) => ({
  scope,
  name: scope.node.name,
  context: contexts[i]
}));
```

**Why:** `scopeToString` is async but wasn't awaited. This sends Promise objects to OpenAI API instead of strings, causing 400 errors and 100% failure in turbo mode.

**Validation:**
- Functional test created: `src/plugins/openai/openai-turbo.test.ts`
- Test currently FAILS (detecting bug)
- Test will PASS after fix applied
- Run: `tsx --test src/plugins/openai/openai-turbo.test.ts`

**Acceptance Criteria:**
- [ ] Context extraction uses `await Promise.all()`
- [ ] `job.context` is `string`, not `Promise<string>`
- [ ] Parallel extraction preserved (not sequential)
- [ ] No TypeScript errors after change
- [ ] Test `src/plugins/openai/openai-turbo.test.ts` passes (5/5 tests)

---

### 3. Build and Validate Fixes
**Priority:** P0 - CRITICAL
**Effort:** 10 minutes
**Status:** ❌ NOT STARTED

**Commands:**
```bash
# Run new functional tests (should fail before fixes)
tsx --test src/progress.test.ts
tsx --test src/plugins/openai/openai-turbo.test.ts

# Apply fixes to both files
# (Edit src/progress.ts:29 and src/plugins/local-llm-rename/visit-all-identifiers.ts:139-144)

# Re-run tests (should pass after fixes)
tsx --test src/progress.test.ts
tsx --test src/plugins/openai/openai-turbo.test.ts

# Build project
npm run build

# Run benchmark script
export OPENAI_API_KEY="your-key-here"
./benchmark-packages.sh

# Check results
cat benchmark-results/results.csv
```

**Acceptance Criteria:**
- [ ] Functional tests pass after fixes applied
- [ ] Build succeeds without errors
- [ ] Benchmark script runs to completion (no crashes)
- [ ] Normal mode: All packages exit code 0
- [ ] Turbo mode: All packages exit code 0
- [ ] No "cursorTo is not a function" errors
- [ ] No "Invalid type for messages" errors
- [ ] Output files generated for all packages

**Expected Results:**
```
package     size_category  size_bytes  mode    duration_seconds  exit_code
colors      small          39506       normal  XX                0
colors      small          39506       turbo   XX                0
debug       small          42793       normal  XX                0
debug       small          42793       turbo   XX                0
...
```

All `exit_code` values should be `0`.

---

## Functional Tests Created (NEW!)

### ✅ Test Files Created and Validated

**Status:** Tests created and verified to detect bugs

#### Bug #1 Test: `src/progress.test.ts`
- **Location:** `/Users/bmf/Library/Mobile Documents/com~apple~CloudDocs/_mine/icode/brandon-fryslie_humanify/src/progress.test.ts`
- **Test Cases:** 4
- **Current Status:** 2/4 PASS, 2/4 FAIL (correctly detecting bug)
- **Expected After Fix:** 4/4 PASS
- **Run:** `tsx --test src/progress.test.ts`

**Test Cases:**
1. ❌ `showPercentage should not crash when stdout is redirected (Bug #1)` - PRIMARY TEST
2. ✅ `showPercentage should work normally when stdout is a TTY`
3. ✅ `showPercentage should use verbose logging when verbose.enabled is true`
4. ❌ `showPercentage should handle partial TTY method availability`

**Why Un-Gameable:**
- Actually removes TTY methods from process.stdout (simulates pipe redirection)
- Invokes real production function (not mocked)
- Uses assert.doesNotThrow to verify observable outcome
- Cannot be satisfied without adding optional chaining

---

#### Bug #2 Test: `src/plugins/openai/openai-turbo.test.ts`
- **Location:** `/Users/bmf/Library/Mobile Documents/com~apple~CloudDocs/_mine/icode/brandon-fryslie_humanify/src/plugins/openai/openai-turbo.test.ts`
- **Test Cases:** 5
- **Current Status:** 1/5 PASS, 4/5 FAIL (correctly detecting bug)
- **Expected After Fix:** 5/5 PASS
- **Run:** `tsx --test src/plugins/openai/openai-turbo.test.ts`

**Test Cases:**
1. ❌ `turbo mode should pass string context (not Promise) to visitor function (Bug #2)` - PRIMARY TEST
2. ❌ `turbo mode should handle async context extraction correctly`
3. ❌ `turbo and sequential modes should both pass string contexts`
4. ✅ `documentation: Promise serialization would fail OpenAI API validation`
5. ❌ `turbo mode should process contexts in parallel (performance characteristic)`

**Why Un-Gameable:**
- Uses visitor that INSPECTS surroundingCode parameter (not ignores it)
- Validates TYPE of parameter (typeof === "string")
- Checks for Promise methods (.then)
- Verifies actual code content
- Cannot be satisfied without adding await

---

### Test Documentation Created

**Files:**
1. `TEST_VALIDATION.md` - Detailed test documentation and methodology
2. `FUNCTIONAL_TESTS_SUMMARY.md` - Executive summary and validation results

**Key Points:**
- Tests detect exact production failure modes
- Tests cannot be gamed with stubs or mocks
- Tests fail NOW, will pass AFTER fixes
- Tests provide regression protection

---

## High Priority Testing (P1 - HIGH)

### 4. Run Full Test Suite
**Priority:** P1 - HIGH
**Effort:** 5 minutes
**Status:** ❌ NOT STARTED

**Commands:**
```bash
# Run all tests (includes new functional tests)
npm test

# Run specific suites
npm run test:unit  # Includes our new .test.ts files
npm run test:e2e
npm run test:llm   # If API keys available

# Check linting
npm run lint

# Type check
npx tsc --noEmit
```

**Acceptance Criteria:**
- [ ] All existing tests pass (no regressions)
- [ ] New functional tests pass (Bug #1 and Bug #2)
- [ ] No TypeScript errors
- [ ] No linting errors
- [ ] Build succeeds

---

### 5. Add Additional E2E Test (Optional)
**File:** Create `/Users/bmf/Library/Mobile Documents/com~apple~CloudDocs/_mine/icode/brandon-fryslie_humanify/src/progress.e2etest.ts`
**Priority:** P1 - HIGH (Optional - we already have unit test for Bug #1)
**Effort:** 15 minutes
**Status:** ⚠️ OPTIONAL (unit test already validates Bug #1)

**Purpose:** Verify CLI doesn't crash when stdout is redirected (E2E validation)

**Note:** The functional test `src/progress.test.ts` already validates Bug #1 at the unit level. This E2E test would provide additional confidence by running the full CLI, but is not required for bug validation.

**Key Tests:**
```typescript
it("should not crash when stdout is redirected to file", async () => {
  const result = await runCLI(["openai", inputFile, "-o", outputFile], {
    redirectStdout: true
  });

  assert.strictEqual(result.exitCode, 0);
  assert.ok(!result.stderr.includes("cursorTo"));
});
```

---

## Optional Improvements (P2 - MEDIUM)

### 6. Refactor: Remove Async from scopeToString
**File:** `/Users/bmf/Library/Mobile Documents/com~apple~CloudDocs/_mine/icode/brandon-fryslie_humanify/src/plugins/local-llm-rename/visit-all-identifiers.ts`
**Priority:** P2 - MEDIUM
**Effort:** 20 minutes
**Status:** ❌ NOT STARTED

**Why:** Function is marked `async` but contains no `await` statements. Unnecessary Promise overhead.

**Changes:**
- Remove `async` keyword from function signature (line 207)
- Change return type from `Promise<string>` to `string`
- Remove `await` from call site in sequential mode (line 90)
- Simplify turbo mode context extraction (no Promise.all needed)

**Acceptance Criteria:**
- [ ] Function is synchronous
- [ ] All call sites updated
- [ ] All tests pass
- [ ] Performance improvement (no Promise allocation)

---

### 7. Refactor: Progress Reporter Interface
**File:** `/Users/bmf/Library/Mobile Documents/com~apple~CloudDocs/_mine/icode/brandon-fryslie_humanify/src/progress.ts`
**Priority:** P2 - MEDIUM
**Effort:** 1 hour
**Status:** ❌ NOT STARTED

**Why:** Current design directly accesses `process.stdout`, making it untestable and inflexible.

**Changes:**
- Create `ProgressReporter` interface
- Implement `TTYProgressReporter` (current behavior)
- Implement `LogProgressReporter` (for redirected stdout)
- Implement `SilentProgressReporter` (for tests)
- Auto-detect based on `process.stdout.isTTY`

**Acceptance Criteria:**
- [ ] Interface and implementations created
- [ ] All call sites updated
- [ ] Behavior unchanged (externally observable)
- [ ] New unit tests for each implementation
- [ ] All tests pass

---

### 8. Add Benchmark Script to CI
**File:** Create `.github/workflows/benchmark.yml`
**Priority:** P2 - MEDIUM
**Effort:** 30 minutes
**Status:** ❌ NOT STARTED

**Why:** Automate production validation to catch bugs before merge.

**Changes:**
- Create GitHub Actions workflow
- Run on pull requests and weekly schedule
- Use reduced package set for fast feedback (colors + commander)
- Upload results as artifacts
- Fail workflow if any package exits non-zero

**Acceptance Criteria:**
- [ ] Workflow file created
- [ ] Runs on PR and schedule
- [ ] Uses CI mode (reduced packages)
- [ ] Results uploaded as artifacts
- [ ] Workflow fails if benchmarks fail

---

## Progress Tracking

**P0 Tasks (Must Complete):**
- [ ] 1. Fix Bug #1 (progress.ts)
- [ ] 2. Fix Bug #2 (visit-all-identifiers.ts)
- [ ] 3. Validate with benchmark script
- [x] ✅ Create functional tests (COMPLETED)

**P1 Tasks (Highly Recommended):**
- [ ] 4. Run full test suite
- [~] 5. E2E test (OPTIONAL - unit test already validates)

**P2 Tasks (Optional):**
- [ ] 6. Refactor scopeToString
- [ ] 7. Refactor progress reporter
- [ ] 8. Add benchmark to CI

---

## Test Validation Status

### Current Test Results (Before Fixes)

**Bug #1 Test:**
```bash
$ tsx --test src/progress.test.ts
# tests 4
# pass 2
# fail 2  ← Expected failures (bug detected)
```

**Bug #2 Test:**
```bash
$ tsx --test src/plugins/openai/openai-turbo.test.ts
# tests 5
# pass 1
# fail 4  ← Expected failures (bug detected)
```

**Conclusion:** Tests are working as designed. They detect both bugs and will validate when fixes are applied.

---

## Quick Start Guide

**To fix the bugs immediately:**

```bash
# 1. Navigate to project
cd ~/icode/brandon-fryslie_humanify

# 2. Verify tests detect bugs (should fail)
tsx --test src/progress.test.ts                          # 2/4 fail expected
tsx --test src/plugins/openai/openai-turbo.test.ts      # 4/5 fail expected

# 3. Open files and make changes
# Edit src/progress.ts line 29: Add ?. operator
# Edit src/plugins/local-llm-rename/visit-all-identifiers.ts lines 139-144: Add await

# 4. Verify tests pass after fixes
tsx --test src/progress.test.ts                          # 4/4 pass expected
tsx --test src/plugins/openai/openai-turbo.test.ts      # 5/5 pass expected

# 5. Build and test
npm run build
export OPENAI_API_KEY="your-key-here"
./benchmark-packages.sh

# 6. Verify success
cat benchmark-results/results.csv
# All exit_code columns should be 0

# 7. Run full test suite
npm test

# 8. Commit
git add src/progress.ts src/plugins/local-llm-rename/visit-all-identifiers.ts \
        src/progress.test.ts src/plugins/openai/openai-turbo.test.ts \
        TEST_VALIDATION.md FUNCTIONAL_TESTS_SUMMARY.md

git commit -m "fix: add optional chaining for redirected stdout and await for turbo mode context extraction

- Fix progress.ts cursorTo crash when stdout is redirected
- Fix turbo mode Promise serialization bug in context extraction
- Add functional tests to validate both bug fixes
- Both bugs caused 100% failure rate in benchmark tests

Tests:
- src/progress.test.ts validates Bug #1 fix (4 test cases)
- src/plugins/openai/openai-turbo.test.ts validates Bug #2 fix (5 test cases)
- All tests are un-gameable and validate real user workflows"
```

---

## Success Criteria

**Session is complete when:**
- ✅ Functional tests created (COMPLETED)
- ✅ Tests detect bugs (VERIFIED - tests fail as expected)
- [ ] Both bugs fixed (2 files modified)
- [ ] Tests pass after fixes (2 test files, 9 test cases)
- [ ] Benchmark script runs successfully (all exit codes = 0)
- [ ] All tests passing (npm test = 100%)
- [ ] Code committed with descriptive message

**Production is unblocked when:**
- [ ] Normal mode works with redirected stdout
- [ ] Turbo mode works with real LLM providers
- [ ] 6/6 packages succeed in benchmark (currently 0/6)
- [ ] Functional tests provide regression protection

---

## Summary of Work Completed

### ✅ Functional Tests Created (2025-10-23)

**Files Created:**
1. `src/progress.test.ts` (159 lines, 4 test cases)
2. `src/plugins/openai/openai-turbo.test.ts` (352 lines, 5 test cases)
3. `TEST_VALIDATION.md` (comprehensive test documentation)
4. `FUNCTIONAL_TESTS_SUMMARY.md` (executive summary)

**Total:** 511 lines of test code, 9 test cases

**Test Quality:**
- ✅ Un-gameable (cannot be satisfied by stubs)
- ✅ Real execution paths (invoke actual production code)
- ✅ Observable outcomes (verify user-visible behavior)
- ✅ Fail fast (detect bugs immediately)
- ✅ Regression protection (future changes won't reintroduce bugs)

**Validation Results:**
- Bug #1: 2/4 tests fail (detecting missing optional chaining)
- Bug #2: 4/5 tests fail (detecting Promise instead of string)
- Tests will pass after one-line fixes are applied

**Next Steps:**
1. Apply bug fixes (2 files, ~5 lines total)
2. Verify tests pass
3. Run benchmark script
4. Commit changes

---

## Notes

- All P0 tasks are **simple fixes** (1-2 lines each)
- **Zero risk** - strictly additive changes
- **High impact** - unblocks 100% of production use
- **Tests validated** - functional tests detect both bugs
- Total time to production-ready: **~1 hour**
- P2 tasks are **optional** - can defer to follow-up work
