# Bug Fix Implementation Plan
**Generated:** 2025-10-23 16:47:27
**Source STATUS:** STATUS-2025-10-23-164430.md
**Spec Version:** CLAUDE.md (last modified: 2025-10-23)

---

## Executive Summary

This plan addresses **two critical production-blocking bugs** identified in the benchmark evaluation:

1. **Bug #1 (Normal Mode)**: Missing optional chaining in `src/progress.ts:29` causes crashes when stdout is redirected (100% failure rate in benchmark)
2. **Bug #2 (Turbo Mode)**: Missing await in `src/plugins/local-llm-rename/visit-all-identifiers.ts:143` sends Promise objects to OpenAI API instead of strings (100% failure rate in turbo mode)

Both bugs are **simple fixes** (1-2 lines each) but have **severe impact** (prevent all production use). The root cause is a **test coverage gap**: unit tests pass but don't exercise real-world scenarios (redirected stdout, real LLM provider integration in turbo mode).

**Current State:**
- 0/6 packages succeed in normal mode
- 0/6 packages succeed in turbo mode
- Test suite: 100% passing (misleading)

**Target State:**
- All benchmark tests passing
- Regression tests added to prevent similar bugs
- Code quality improvements in affected areas

---

## Priority Matrix

### P0 - CRITICAL (Production Blocking)
**Must complete before ANY other work**

1. Fix Bug #1 (progress.ts)
2. Fix Bug #2 (visit-all-identifiers.ts)
3. Validate fixes with benchmark script

### P1 - HIGH (Quality & Reliability)
**Should complete in same session as P0**

4. Add integration test: Turbo mode + real provider
5. Add E2E test: Redirected stdout behavior
6. Run full test suite to ensure no regressions

### P2 - MEDIUM (Technical Debt)
**Can defer to follow-up work**

7. Refactor scopeToString (remove unnecessary async)
8. Improve progress.ts architecture
9. Add benchmark script to CI

---

## Detailed Work Items

---

## [P0 - CRITICAL] Fix Bug #1: Terminal API Failure (Normal Mode)

**Status**: Not Started
**Effort**: 1 minute
**Dependencies**: None
**Spec Reference**: CLAUDE.md "Progress reporting" • **STATUS Reference**: STATUS-2025-10-23-164430.md, Lines 23-84

### Description

Add missing optional chaining to `process.stdout.cursorTo()` call in `src/progress.ts:29`. When stdout is redirected (piped to `tee` or file), the `cursorTo` method doesn't exist, causing uncaught TypeError that crashes the process.

**Current Code (Line 29):**
```typescript
process.stdout.cursorTo(0);  // ❌ No optional chaining
```

**Root Cause:** Line 28 correctly uses optional chaining for `clearLine?.()`, but line 29 doesn't. This inconsistency suggests the fix was attempted but incomplete.

**Evidence:** 6/6 packages failed with identical error:
```
TypeError: process.stdout.cursorTo is not a function
    at showPercentage (file:///.../dist/index.mjs:51269:20)
```

### Acceptance Criteria

- [ ] Add optional chaining to `process.stdout.cursorTo?.(0)` at line 29
- [ ] Line 28 and 29 are now consistent (both use optional chaining)
- [ ] Code compiles without TypeScript errors
- [ ] Benchmark script completes without crashes in normal mode
- [ ] Progress reporting works correctly when:
  - [ ] stdout is a TTY (interactive terminal)
  - [ ] stdout is redirected to file (`> output.txt`)
  - [ ] stdout is piped (`| tee log.txt`)

### Technical Notes

**Fix:**
```typescript
export function showPercentage(percentage: number) {
  const percentageStr = Math.round(percentage * 100);
  if (!verbose.enabled) {
    process.stdout.clearLine?.(0);   // ✅ Already has optional chaining
    process.stdout.cursorTo?.(0);    // ✅ ADD optional chaining here
    process.stdout.write(`Processing: ${percentageStr}%`);
  } else {
    verbose.log(`Processing: ${percentageStr}%`);
  }
  if (percentage === 1) {
    process.stdout.write("\n");
  }
}
```

**Why This Works:**
- Optional chaining (`?.`) returns `undefined` if method doesn't exist
- No error thrown, execution continues
- Progress updates simply don't display when stdout is redirected (acceptable behavior)

**Risk Assessment:** ZERO - This is a strictly additive change that makes the code more defensive.

---

## [P0 - CRITICAL] Fix Bug #2: Missing Await (Turbo Mode)

**Status**: Not Started
**Effort**: 5 minutes
**Dependencies**: None
**Spec Reference**: CLAUDE.md "Turbo Mode - Parallel Batch Execution" • **STATUS Reference**: STATUS-2025-10-23-164430.md, Lines 87-193

### Description

Add missing `await` when calling async `scopeToString()` function in turbo mode. Currently, the function is called without await, causing `job.context` to be a Promise object instead of a string. This Promise is then serialized and sent to OpenAI API, which rejects it with a 400 error.

**Current Code (Lines 139-144):**
```typescript
// Extract contexts at current AST state (before parallel API calls)
const jobs = toProcess.map((scope) => ({
  scope,
  name: scope.node.name,
  context: scopeToString(scope, contextWindowSize)  // ❌ Missing await
}));
```

**Comparison - Sequential Mode (CORRECT - Lines 90-93):**
```typescript
const surroundingCode = await scopeToString(  // ✅ Correctly awaited
  smallestScope,
  contextWindowSize
);
const renamed = await visitor(smallestScopeNode.name, surroundingCode);
```

**Evidence:** All turbo mode executions fail immediately:
```
BadRequestError: 400 Invalid type for 'messages[1].content':
expected one of a string or array of objects, but got an object instead.
```

### Acceptance Criteria

- [ ] Context extraction is properly awaited (all Promises resolved)
- [ ] `job.context` contains string values, not Promise objects
- [ ] Code compiles without TypeScript errors
- [ ] OpenAI API receives valid string context (not serialized Promise)
- [ ] Benchmark script completes without crashes in turbo mode
- [ ] Performance characteristics preserved:
  - [ ] Context extraction happens in parallel (not sequential)
  - [ ] Batch processing maintains concurrency control

### Technical Notes

**Fix (Option 2 - RECOMMENDED - Maintains Parallelization):**

```typescript
// Extract all contexts in parallel (line 139-144)
const contexts = await Promise.all(
  toProcess.map(scope => scopeToString(scope, contextWindowSize))
);

// Build jobs with resolved contexts
const jobs = toProcess.map((scope, i) => ({
  scope,
  name: scope.node.name,
  context: contexts[i]
}));
```

**Why Option 2 (Not Option 1):**
- **Option 1** (sequential await inside map): `await Promise.all(toProcess.map(async (scope) => ({ ... await scopeToString() ... })))`
  - Simple but defeats parallelization purpose
  - Each `scopeToString` call is a synchronous operation (despite being marked async)
  - No benefit to awaiting them sequentially inside the map

- **Option 2** (parallel extraction):
  - Maintains performance characteristics
  - Clearer separation of concerns: extract all contexts → build jobs
  - More readable and debuggable
  - Future-proof if `scopeToString` becomes truly async

**Why Tests Missed This:**

From `src/plugins/local-llm-rename/turbo-mode.test.ts`:
```typescript
async (name) => name + "_renamed"  // Ignores surroundingCode parameter
```

Tests use mock visitors that ignore the second parameter, so they never inspect the `surroundingCode` value. The Promise object is never used, so the bug goes undetected.

**Risk Assessment:** LOW - Isolated change with clear before/after behavior. The fix makes the code do what it was always intended to do.

---

## [P0 - CRITICAL] Validate Fixes with Benchmark Script

**Status**: Not Started
**Effort**: 10 minutes
**Dependencies**: Bug #1 fixed, Bug #2 fixed
**Spec Reference**: CLAUDE.md "Testing" • **STATUS Reference**: STATUS-2025-10-23-164430.md, Lines 439-468

### Description

Run the benchmark script (`benchmark-packages.sh`) to verify both bugs are fixed and production scenarios now work correctly. This validates the fixes against real-world usage patterns that the test suite missed.

### Acceptance Criteria

- [ ] Build project successfully: `npm run build`
- [ ] Benchmark script runs to completion without crashes
- [ ] Normal mode results:
  - [ ] 6/6 packages process successfully (exit code 0)
  - [ ] Output files generated for all packages
  - [ ] No "cursorTo is not a function" errors
- [ ] Turbo mode results:
  - [ ] 6/6 packages process successfully (exit code 0)
  - [ ] Output files generated for all packages
  - [ ] No "Invalid type for messages" errors
- [ ] Results CSV generated with success metrics
- [ ] Log files contain normal progress output (no errors)
- [ ] Output files are valid JavaScript (parseable)

### Technical Notes

**Validation Commands:**
```bash
# Build the project
npm run build

# Run benchmark (requires OPENAI_API_KEY)
export OPENAI_API_KEY="your-key-here"
./benchmark-packages.sh

# Check results
cat benchmark-results/results.csv
ls -la benchmark-results/*/normal/output.js
ls -la benchmark-results/*/turbo/output.js

# Verify no errors in logs
grep -i error benchmark-results/*/normal/log.txt
grep -i error benchmark-results/*/turbo/log.txt
```

**Expected Output:**
```
=== Benchmark Complete ===
Results saved to benchmark-results/

Summary:
package     size_category  size_bytes  mode    duration_seconds  exit_code
colors      small          39506       normal  15                0
colors      small          39506       turbo   8                 0
debug       small          42793       normal  18                0
debug       small          42793       turbo   9                 0
commander   medium         208150      normal  45                0
commander   medium         208150      turbo   20                0
glob        medium         475171      normal  90                0
glob        medium         475171      turbo   35                0
axios       large          2241796     normal  180               0
axios       large          2241796     turbo   65                0
vue         large          2420929     normal  200               0
vue         large          2420929     turbo   70                0
```

**Success Criteria:** All `exit_code` values should be `0`.

**Risk Assessment:** ZERO - This is a read-only validation step. If it fails, we've identified the issue before proceeding.

---

## [P1 - HIGH] Add Integration Test: Turbo Mode + Real Provider

**Status**: Not Started
**Effort**: 30 minutes
**Dependencies**: Bug #2 fixed
**Spec Reference**: CLAUDE.md "Test Patterns" • **STATUS Reference**: STATUS-2025-10-23-164430.md, Lines 228-246

### Description

Add integration test that exercises turbo mode with a real LLM provider plugin (OpenAI or Gemini) using mocked HTTP responses. This closes the test coverage gap that allowed Bug #2 to slip through.

**Current Gap:** Turbo mode tests (`turbo-mode.test.ts`) use mock visitors that ignore the `surroundingCode` parameter. When real providers receive a Promise object instead of a string, they serialize it and send it to the API, which fails.

### Acceptance Criteria

- [ ] New test file created: `src/plugins/local-llm-rename/turbo-integration.test.ts`
- [ ] Test imports real OpenAI plugin (not mock visitor)
- [ ] HTTP responses are mocked (no actual API calls)
- [ ] Test verifies:
  - [ ] `surroundingCode` parameter is a string (not Promise)
  - [ ] OpenAI API receives valid message format
  - [ ] Renamed identifiers are applied correctly
  - [ ] No TypeScript type errors (Promise vs string)
- [ ] Test runs in `npm test` (not just llmtest)
- [ ] Test fails if `await` is removed from context extraction (regression test)

### Technical Notes

**Test Structure:**

```typescript
import { describe, it, mock } from "node:test";
import assert from "node:assert";
import { visitAllIdentifiers } from "./visit-all-identifiers.js";
import { createRenameVisitor } from "../openai/openai-rename.js";

describe("Turbo mode integration with real provider", () => {
  it("should pass string context (not Promise) to OpenAI plugin", async () => {
    // Mock OpenAI HTTP endpoint
    const mockFetch = mock.fn(async (url, options) => {
      const body = JSON.parse(options.body);

      // CRITICAL: Verify messages contain strings, not Promise objects
      const userMessage = body.messages[1].content;
      assert.strictEqual(typeof userMessage, "string",
        "Expected string context, got: " + typeof userMessage);
      assert.ok(!userMessage.includes("[object Promise]"),
        "Context contains serialized Promise");

      // Return mock response
      return {
        ok: true,
        json: async () => ({
          choices: [{
            message: {
              content: JSON.stringify({ newName: "renamedVar" })
            }
          }]
        })
      };
    });

    global.fetch = mockFetch as any;

    const code = `function example() { const abc = 1; return abc; }`;
    const visitor = createRenameVisitor({ apiKey: "test-key" });

    const result = await visitAllIdentifiers(
      code,
      visitor,
      1000,
      undefined,
      { turbo: true, maxConcurrent: 2 }
    );

    // Verify rename applied
    assert.ok(result.includes("renamedVar"));
    assert.ok(!result.includes("abc"));

    // Verify fetch was called
    assert.ok(mockFetch.mock.calls.length > 0);
  });
});
```

**Why This Test Would Have Caught Bug #2:**
1. Uses real OpenAI plugin (inspects `surroundingCode` parameter)
2. Mocked fetch validates message structure
3. Type assertion fails if Promise object is passed
4. String checks detect serialized Promise (`[object Promise]`)

**Risk Assessment:** ZERO - New test, no production code changes.

---

## [P1 - HIGH] Add E2E Test: Redirected Stdout Behavior

**Status**: Not Started
**Effort**: 15 minutes
**Dependencies**: Bug #1 fixed
**Spec Reference**: CLAUDE.md "Testing" • **STATUS Reference**: STATUS-2025-10-23-164430.md, Lines 228-246

### Description

Add end-to-end test that runs the built CLI with redirected stdout to verify progress reporting doesn't crash. This closes the test coverage gap that allowed Bug #1 to slip through.

**Current Gap:** No tests verify behavior when stdout is piped or redirected. Production usage (CI/CD, logging, benchmarks) always redirects stdout.

### Acceptance Criteria

- [ ] New test file created: `src/progress.e2etest.ts`
- [ ] Test builds project before running (ensures CLI is up to date)
- [ ] Test executes CLI with stdout redirected:
  - [ ] Piped to file (`> output.txt`)
  - [ ] Piped through tee (`| tee log.txt`)
  - [ ] Piped to null (`> /dev/null`)
- [ ] Test verifies:
  - [ ] Exit code is 0 (no crash)
  - [ ] No "cursorTo is not a function" error in output
  - [ ] Output file is generated correctly
  - [ ] Log file (if using tee) contains progress updates or is silent
- [ ] Test runs in `npm run test:e2e`
- [ ] Test fails if optional chaining is removed (regression test)

### Technical Notes

**Test Structure:**

```typescript
import { describe, it } from "node:test";
import assert from "node:assert";
import { spawn } from "node:child_process";
import { readFile, writeFile, unlink } from "node:fs/promises";
import { tmpdir } from "node:os";
import { join } from "node:path";

describe("Progress reporting with redirected stdout", () => {
  const testCode = `function test() { const x = 1; return x; }`;

  it("should not crash when stdout is redirected to file", async () => {
    const inputFile = join(tmpdir(), "test-input.js");
    const outputFile = join(tmpdir(), "test-output.js");
    const logFile = join(tmpdir(), "test-log.txt");

    await writeFile(inputFile, testCode);

    // Run CLI with stdout redirected to log file
    const result = await new Promise<{code: number, stderr: string}>((resolve) => {
      const proc = spawn(
        "./dist/index.mjs",
        ["openai", inputFile, "-o", outputFile],
        {
          env: { ...process.env, OPENAI_API_KEY: "test-key" },
          shell: true,
          stdio: ["ignore", "pipe", "pipe"]
        }
      );

      let stderr = "";
      proc.stderr.on("data", (data) => { stderr += data.toString(); });

      // Redirect stdout to file
      const logStream = fs.createWriteStream(logFile);
      proc.stdout.pipe(logStream);

      proc.on("close", (code) => {
        logStream.end();
        resolve({ code: code ?? 1, stderr });
      });
    });

    // Verify success
    assert.strictEqual(result.code, 0, `CLI crashed: ${result.stderr}`);
    assert.ok(!result.stderr.includes("cursorTo"),
      "cursorTo error found in stderr");

    // Verify output file exists
    const output = await readFile(outputFile, "utf-8");
    assert.ok(output.length > 0);

    // Cleanup
    await unlink(inputFile);
    await unlink(outputFile);
    await unlink(logFile);
  });

  it("should not crash when stdout is piped", async () => {
    const inputFile = join(tmpdir(), "test-input-pipe.js");
    const outputFile = join(tmpdir(), "test-output-pipe.js");

    await writeFile(inputFile, testCode);

    // Run CLI with stdout piped (simulates | tee)
    const result = await new Promise<{code: number, stdout: string, stderr: string}>((resolve) => {
      const proc = spawn(
        "./dist/index.mjs",
        ["openai", inputFile, "-o", outputFile],
        {
          env: { ...process.env, OPENAI_API_KEY: "test-key" },
          shell: true,
          stdio: ["ignore", "pipe", "pipe"]
        }
      );

      let stdout = "";
      let stderr = "";
      proc.stdout.on("data", (data) => { stdout += data.toString(); });
      proc.stderr.on("data", (data) => { stderr += data.toString(); });

      proc.on("close", (code) => {
        resolve({ code: code ?? 1, stdout, stderr });
      });
    });

    // Verify success
    assert.strictEqual(result.code, 0, `CLI crashed: ${result.stderr}`);
    assert.ok(!result.stderr.includes("cursorTo"),
      "cursorTo error found in stderr");
    assert.ok(!result.stderr.includes("TypeError"),
      "TypeError found in stderr");

    // Cleanup
    await unlink(inputFile);
    await unlink(outputFile);
  });
});
```

**Why This Test Would Have Caught Bug #1:**
1. Redirects stdout (removes TTY capability)
2. Executes real CLI binary (not mocked)
3. Checks for specific error message
4. Validates exit code (non-zero if crash)

**Alternative Approach (Simpler but Less Realistic):**

```typescript
// Unit test approach: Mock process.stdout
it("should handle missing cursorTo method", () => {
  const originalCursorTo = process.stdout.cursorTo;
  const originalClearLine = process.stdout.clearLine;

  try {
    // Simulate redirected stdout (remove TTY methods)
    delete (process.stdout as any).cursorTo;
    delete (process.stdout as any).clearLine;

    // Should not throw
    assert.doesNotThrow(() => {
      showPercentage(0.5);
      showPercentage(1.0);
    });
  } finally {
    // Restore
    (process.stdout as any).cursorTo = originalCursorTo;
    (process.stdout as any).clearLine = originalClearLine;
  }
});
```

**Recommendation:** Use both approaches:
- Unit test for fast feedback during development
- E2E test for production confidence

**Risk Assessment:** ZERO - New test, no production code changes.

---

## [P1 - HIGH] Run Full Test Suite

**Status**: Not Started
**Effort**: 5 minutes
**Dependencies**: All P0 and P1 fixes applied
**Spec Reference**: CLAUDE.md "Testing" • **STATUS Reference**: STATUS-2025-10-23-164430.md, Lines 413-434

### Description

Run the complete test suite to ensure the bug fixes and new tests don't introduce regressions. All existing tests should continue to pass.

### Acceptance Criteria

- [ ] All test suites pass:
  - [ ] `npm run test:unit` - 100% pass
  - [ ] `npm run test:e2e` - 100% pass
  - [ ] `npm run test:llm` - 100% pass (if API keys available)
- [ ] No new TypeScript errors
- [ ] No new linting errors
- [ ] Build succeeds: `npm run build`
- [ ] New integration tests are executed
- [ ] Test coverage report shows coverage of modified lines

### Technical Notes

**Validation Commands:**

```bash
# Clean build
npm run build

# Run all tests
npm test

# Run specific suites
npm run test:unit
npm run test:e2e

# Check linting
npm run lint

# Type check
npx tsc --noEmit
```

**Expected Results:**
- All existing tests pass (no behavior changes)
- 2 new tests pass (turbo integration + stdout redirect)
- No warnings or errors

**If Tests Fail:** Investigate immediately - this suggests unintended side effects from the fixes.

**Risk Assessment:** ZERO - Validation step only.

---

## [P2 - MEDIUM] Refactor: Remove Async from scopeToString

**Status**: Not Started
**Effort**: 20 minutes
**Dependencies**: All P0 and P1 complete
**Spec Reference**: N/A (Technical Debt) • **STATUS Reference**: STATUS-2025-10-23-164430.md, Lines 195-225

### Description

The `scopeToString` function is marked `async` but contains no `await` statements. This forces unnecessary Promise wrapping and adds cognitive load. Either remove the `async` keyword or document why it's needed.

**Current Signature (Line 207):**
```typescript
async function scopeToString(
  path: NodePath<Identifier>,
  contextWindowSize: number
) {
  // ... only synchronous operations ...
  return code;  // Synchronous return
}
```

**Analysis:** All operations inside the function are synchronous:
- `closestSurroundingContextPath(path)` - synchronous
- String conversion (`${surroundingPath}`) - synchronous
- String slicing and manipulation - synchronous

### Acceptance Criteria

**Option A: Remove async (RECOMMENDED)**
- [ ] Remove `async` keyword from function signature
- [ ] Update all call sites to remove `await`
- [ ] All tests pass
- [ ] Function returns `string` instead of `Promise<string>`
- [ ] Performance improvement (no Promise allocation)

**Option B: Document why async**
- [ ] Add JSDoc comment explaining why function is async
- [ ] Justify the Promise overhead
- [ ] Document future plans that require async

### Technical Notes

**Impact Analysis:**

Call sites to update:
1. `visit-all-identifiers.ts:90` - Sequential mode: `await scopeToString(...)`
2. `visit-all-identifiers.ts:143` - Turbo mode: `scopeToString(...)` (within Promise.all)

**Option A Implementation:**

```typescript
// Remove async keyword
function scopeToString(
  path: NodePath<Identifier>,
  contextWindowSize: number
): string {  // Change return type from Promise<string> to string
  const surroundingPath = closestSurroundingContextPath(path);
  const code = `${surroundingPath}`;
  // ... rest unchanged ...
  return code;
}

// Update call sites
// Sequential mode (line 90):
const surroundingCode = scopeToString(  // Remove await
  smallestScope,
  contextWindowSize
);

// Turbo mode (line 140-144):
const jobs = toProcess.map((scope) => ({  // No Promise.all needed
  scope,
  name: scope.node.name,
  context: scopeToString(scope, contextWindowSize)  // Synchronous call
}));
```

**Benefits:**
- Eliminates unnecessary Promise overhead
- Clearer code (synchronous operations don't hide async complexity)
- Easier to understand and debug
- Slight performance improvement

**Risks:**
- Breaking change if external code depends on this function
- Currently no evidence of external usage (internal function)
- All call sites are in the same file

**Why P2 (Not P0/P1):**
- Not production-blocking
- Code works correctly as-is (just suboptimal)
- Can defer to follow-up work
- Requires careful testing of all code paths

**Risk Assessment:** MEDIUM - Touches core logic in multiple places. Thorough testing required.

---

## [P2 - MEDIUM] Refactor: Progress Reporter Interface

**Status**: Not Started
**Effort**: 1 hour
**Dependencies**: All P0 and P1 complete
**Spec Reference**: N/A (Technical Debt) • **STATUS Reference**: STATUS-2025-10-23-164430.md, Lines 248-286

### Description

Current `progress.ts` design directly accesses `process.stdout`, making it untestable and inflexible. Refactor to use dependency injection with a `ProgressReporter` interface.

**Current Issues:**
- Tight coupling to Node.js terminal APIs
- Hard to test (requires mocking global process.stdout)
- Hard to redirect to custom reporters (e.g., JSON logs, metrics)
- Mixed concerns (TTY detection + verbose mode + output)

### Acceptance Criteria

- [ ] Create `ProgressReporter` interface
- [ ] Implement `TTYProgressReporter` (existing behavior)
- [ ] Implement `LogProgressReporter` (for redirected stdout)
- [ ] Implement `SilentProgressReporter` (for tests)
- [ ] Auto-detect reporter based on `process.stdout.isTTY`
- [ ] Update all call sites to use reporter interface
- [ ] All tests pass
- [ ] Progress reporting behavior unchanged (externally observable)
- [ ] New unit tests for each reporter implementation

### Technical Notes

**Proposed Design:**

```typescript
// src/progress.ts

export interface ProgressReporter {
  update(percentage: number): void;
  complete(): void;
}

export class TTYProgressReporter implements ProgressReporter {
  update(percentage: number) {
    const percentageStr = Math.round(percentage * 100);
    process.stdout.clearLine?.(0);
    process.stdout.cursorTo?.(0);
    process.stdout.write(`Processing: ${percentageStr}%`);
  }

  complete() {
    process.stdout.write("\n");
  }
}

export class LogProgressReporter implements ProgressReporter {
  private lastReported = 0;

  update(percentage: number) {
    const percentageInt = Math.round(percentage * 100);
    // Only log every 10% to avoid spam
    if (percentageInt >= this.lastReported + 10) {
      console.log(`Processing: ${percentageInt}%`);
      this.lastReported = percentageInt;
    }
  }

  complete() {
    console.log("Processing: 100%");
  }
}

export class SilentProgressReporter implements ProgressReporter {
  update(_percentage: number) {
    // No-op
  }

  complete() {
    // No-op
  }
}

export function createProgressReporter(verbose: boolean): ProgressReporter {
  if (verbose) {
    return new LogProgressReporter();
  }
  if (process.stdout.isTTY) {
    return new TTYProgressReporter();
  }
  return new SilentProgressReporter();
}

// Backward compatibility wrapper
export function showPercentage(percentage: number) {
  const reporter = createProgressReporter(verbose.enabled);
  reporter.update(percentage);
  if (percentage === 1) {
    reporter.complete();
  }
}
```

**Benefits:**
- Testable (inject mock reporter)
- Flexible (easy to add custom reporters)
- Respects output redirection automatically
- Single Responsibility Principle (each reporter has one job)
- Open/Closed Principle (extend via new implementations)

**Migration Path:**
1. Add new interfaces/classes alongside existing code
2. Update call sites one by one
3. Add tests for new implementations
4. Remove old `showPercentage` function once all call sites migrated

**Testing:**

```typescript
// Easy to test with interface
it("should report progress at intervals", () => {
  const reporter = new LogProgressReporter();
  const logs: string[] = [];

  // Inject spy
  console.log = (msg: string) => logs.push(msg);

  reporter.update(0.15);  // Should log "15%"
  reporter.update(0.18);  // Should not log (< 10% increment)
  reporter.update(0.25);  // Should log "25%"
  reporter.complete();    // Should log "100%"

  assert.deepEqual(logs, [
    "Processing: 15%",
    "Processing: 25%",
    "Processing: 100%"
  ]);
});
```

**Why P2 (Not P1):**
- Not production-blocking
- Current code works after optional chaining fix
- Architectural improvement (nice-to-have)
- Significant refactoring effort
- Low ROI compared to P0/P1 fixes

**Risk Assessment:** LOW - Can be done incrementally with backward compatibility wrapper.

---

## [P2 - MEDIUM] Add Benchmark Script to CI

**Status**: Not Started
**Effort**: 30 minutes
**Dependencies**: All P0 and P1 complete
**Spec Reference**: N/A (Infrastructure) • **STATUS Reference**: STATUS-2025-10-23-164430.md, Lines 228-246

### Description

Add the benchmark script to CI pipeline to catch production-blocking bugs before they reach main branch. Currently, the benchmark script is treated as ad-hoc tooling but it's actually production validation.

**Current Gap:** Benchmark script discovered both bugs, but it's not automated. CI would have caught these before merge.

### Acceptance Criteria

- [ ] New GitHub Actions workflow: `.github/workflows/benchmark.yml`
- [ ] Workflow runs on:
  - [ ] Pull requests (to `main`)
  - [ ] Scheduled (weekly - to catch API breaking changes)
- [ ] Workflow steps:
  - [ ] Checkout code
  - [ ] Setup Node.js
  - [ ] Install dependencies
  - [ ] Build project
  - [ ] Run benchmark script (subset of packages)
  - [ ] Upload results as artifacts
  - [ ] Fail if any package exits with non-zero code
- [ ] Use smaller package set for CI (fast feedback):
  - [ ] 1 small package (colors)
  - [ ] 1 medium package (commander)
- [ ] Results CSV uploaded as artifact
- [ ] Slack/email notification on failure (optional)

### Technical Notes

**Proposed Workflow:**

```yaml
# .github/workflows/benchmark.yml
name: Benchmark Tests

on:
  pull_request:
    branches: [main]
  schedule:
    - cron: '0 0 * * 0'  # Weekly on Sunday
  workflow_dispatch:  # Manual trigger

jobs:
  benchmark:
    runs-on: ubuntu-latest
    timeout-minutes: 30

    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Build project
        run: npm run build

      - name: Run benchmark (CI subset)
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          CI_MODE: 'true'
        run: |
          # Modified benchmark script for CI
          ./benchmark-packages.sh --ci

      - name: Upload benchmark results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: benchmark-results
          path: benchmark-results/
          retention-days: 30

      - name: Check for failures
        run: |
          # Fail if any package failed
          if grep -q ',1$' benchmark-results/results.csv; then
            echo "❌ Benchmark failures detected"
            cat benchmark-results/results.csv
            exit 1
          fi
          echo "✅ All benchmarks passed"
```

**Modified Benchmark Script (CI Mode):**

```bash
# In benchmark-packages.sh, add CI mode flag
if [ "$CI_MODE" = "true" ]; then
  # Use smaller package set for CI
  PACKAGES=(
    "colors:39506"
    "commander:208150"
  )
  echo "Running in CI mode (reduced package set)"
fi
```

**Benefits:**
- Catches production bugs before merge
- Validates real-world usage patterns
- Prevents regressions
- Builds confidence in turbo mode changes
- Documents expected behavior

**Costs:**
- Consumes OpenAI API credits (small cost)
- Adds ~5-10 minutes to CI time
- Requires API key secret configuration

**Alternative: Use Local LLM for CI:**
```yaml
- name: Download CI model
  run: npm run download-ci-model

- name: Run benchmark with local LLM
  run: ./benchmark-packages.sh --ci --provider local
```

**Risk Assessment:** LOW - CI-only addition, no production code changes.

---

## Dependency Graph

```
P0-1: Fix Bug #1 (progress.ts)
  └─> P0-3: Validate Fixes
      └─> P1-5: E2E Test (Redirected Stdout)
          └─> P1-6: Run Full Test Suite
              └─> P2-8: Refactor Progress Reporter
                  └─> P2-9: Add Benchmark to CI

P0-2: Fix Bug #2 (visit-all-identifiers.ts)
  └─> P0-3: Validate Fixes
      └─> P1-4: Integration Test (Turbo + Provider)
          └─> P1-6: Run Full Test Suite
              └─> P2-7: Refactor scopeToString
                  └─> P2-9: Add Benchmark to CI
```

**Critical Path:** P0-1 → P0-2 → P0-3 → P1-4 → P1-5 → P1-6

**Parallelizable:**
- P0-1 and P0-2 can be done simultaneously (independent files)
- P1-4 and P1-5 can be done simultaneously (different test files)
- P2-7 and P2-8 can be done simultaneously (different files)

---

## Recommended Sprint Planning

### Sprint 1: Critical Bug Fixes (30 minutes)
**Goal:** Get benchmarks passing

1. P0-1: Fix Bug #1 (progress.ts) - 1 min
2. P0-2: Fix Bug #2 (visit-all-identifiers.ts) - 5 min
3. P0-3: Validate with benchmark script - 10 min
4. P1-4: Add turbo integration test - 30 min
5. P1-5: Add redirected stdout E2E test - 15 min
6. P1-6: Run full test suite - 5 min

**Deliverables:**
- Both bugs fixed and validated
- Regression tests added
- All tests passing

### Sprint 2: Technical Debt (Optional - 2 hours)
**Goal:** Improve code quality and prevent similar bugs

7. P2-7: Refactor scopeToString - 20 min
8. P2-8: Refactor progress reporter - 1 hour
9. P2-9: Add benchmark to CI - 30 min

**Deliverables:**
- Cleaner architecture
- Better testability
- Automated production validation

---

## Risk Assessment

### High Risk Items
**None** - All P0 fixes are trivial (1-2 lines) with zero risk

### Medium Risk Items
- P2-7 (scopeToString refactor): Touches core logic, requires thorough testing
- P2-8 (progress reporter refactor): Architectural change, but can be incremental

### Low Risk Items
- All P0 and P1 items (additive changes or fixes)
- P2-9 (CI integration): Infrastructure-only

### Mitigation Strategies
- Run full test suite after each change
- Validate with benchmark script before committing
- Use feature flags for P2 refactors (gradual rollout)
- Keep backward compatibility during migrations

---

## Success Metrics

### Immediate (After P0 Complete)
- ✅ Normal mode: 6/6 packages succeed (currently 0/6)
- ✅ Turbo mode: 6/6 packages succeed (currently 0/6)
- ✅ Benchmark script runs to completion (currently crashes immediately)
- ✅ Zero cursorTo errors (currently 100% of runs)
- ✅ Zero Promise serialization errors (currently 100% of turbo runs)

### Short-term (After P1 Complete)
- ✅ Test coverage: Real provider integration tested
- ✅ Test coverage: Redirected stdout scenarios tested
- ✅ All existing tests still passing (no regressions)
- ✅ Build succeeds without warnings

### Long-term (After P2 Complete)
- ✅ CI automatically validates production scenarios
- ✅ Progress reporting uses testable architecture
- ✅ No unnecessary async/Promise overhead
- ✅ Code quality score: 8/10 or higher (currently 3/10 and 6/10)

---

## Blockers and Questions

### Known Blockers
**None** - All fixes are straightforward

### Open Questions

1. **Q:** Should we use Option 1 or Option 2 for Bug #2 fix?
   **A (Recommended):** Option 2 (parallel extraction) - maintains performance and is more readable

2. **Q:** Should we remove async from scopeToString (P2-7)?
   **A (Recommended):** Yes, but defer to Sprint 2. Verify no external dependencies first.

3. **Q:** Should benchmark CI use OpenAI or local LLM?
   **A (Recommended):** Start with local LLM (no API costs), add OpenAI variant for weekly scheduled runs

4. **Q:** What's the priority of P2 items?
   **A:** All optional. P0 and P1 are sufficient to unblock production. P2 improves maintainability.

### Clarifications Needed
**None** - STATUS report provides comprehensive evidence for all issues

---

## File Modification Summary

### Files to Modify (P0 - Required)
1. `/Users/bmf/Library/Mobile Documents/com~apple~CloudDocs/_mine/icode/brandon-fryslie_humanify/src/progress.ts`
   - Line 29: Add optional chaining

2. `/Users/bmf/Library/Mobile Documents/com~apple~CloudDocs/_mine/icode/brandon-fryslie_humanify/src/plugins/local-llm-rename/visit-all-identifiers.ts`
   - Lines 139-144: Add await for context extraction

### Files to Create (P1 - Recommended)
3. `/Users/bmf/Library/Mobile Documents/com~apple~CloudDocs/_mine/icode/brandon-fryslie_humanify/src/plugins/local-llm-rename/turbo-integration.test.ts`
   - New integration test

4. `/Users/bmf/Library/Mobile Documents/com~apple~CloudDocs/_mine/icode/brandon-fryslie_humanify/src/progress.e2etest.ts`
   - New E2E test

### Files to Modify (P2 - Optional)
5. `/Users/bmf/Library/Mobile Documents/com~apple~CloudDocs/_mine/icode/brandon-fryslie_humanify/src/plugins/local-llm-rename/visit-all-identifiers.ts`
   - Remove async from scopeToString (if P2-7 pursued)

6. `/Users/bmf/Library/Mobile Documents/com~apple~CloudDocs/_mine/icode/brandon-fryslie_humanify/src/progress.ts`
   - Refactor to interface (if P2-8 pursued)

7. `/Users/bmf/Library/Mobile Documents/com~apple~CloudDocs/_mine/icode/brandon-fryslie_humanify/benchmark-packages.sh`
   - Add CI mode flag (if P2-9 pursued)

### Files to Create (P2 - Optional)
8. `/Users/bmf/Library/Mobile Documents/com~apple~CloudDocs/_mine/icode/brandon-fryslie_humanify/.github/workflows/benchmark.yml`
   - CI workflow (if P2-9 pursued)

---

## Implementation Checklist

### Phase 1: Critical Fixes (P0) ✅ Must Complete
- [ ] Fix Bug #1: Add optional chaining to progress.ts:29
- [ ] Fix Bug #2: Add await to visit-all-identifiers.ts:139-144
- [ ] Build project: `npm run build`
- [ ] Run benchmark script: `./benchmark-packages.sh`
- [ ] Verify 100% success rate (all exit codes = 0)
- [ ] Commit fixes with message: "fix: add optional chaining for redirected stdout and await for turbo mode context extraction"

### Phase 2: Regression Tests (P1) ✅ Highly Recommended
- [ ] Create turbo integration test (turbo-integration.test.ts)
- [ ] Create redirected stdout E2E test (progress.e2etest.ts)
- [ ] Run full test suite: `npm test`
- [ ] Verify all tests pass (including new tests)
- [ ] Commit tests with message: "test: add regression tests for turbo mode context extraction and redirected stdout"

### Phase 3: Technical Debt (P2) ⚠️ Optional
- [ ] Refactor scopeToString (remove unnecessary async)
- [ ] Refactor progress reporter (add interface)
- [ ] Add benchmark to CI pipeline
- [ ] Run full test suite after each change
- [ ] Commit each refactor separately with descriptive messages

---

## Conclusion

This plan addresses two **critical production-blocking bugs** with simple fixes (1-2 lines each) and comprehensive testing to prevent regressions. The root cause is a **test coverage gap** between unit tests and production usage patterns.

**Immediate action items:**
1. Apply two one-line fixes (5 minutes)
2. Validate with benchmark script (10 minutes)
3. Add regression tests (45 minutes)

**Total time to production-ready:** ~1 hour

**Long-term improvements:**
- CI integration prevents similar bugs
- Architecture refactors improve testability
- Code quality increases from 3-6/10 to 8/10

All changes are low-risk, well-documented, and backed by comprehensive acceptance criteria.
