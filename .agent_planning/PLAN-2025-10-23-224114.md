# Phase 2 Performance Optimization Backlog

**Generated:** 2025-10-23 22:41:14
**Source STATUS:** STATUS-2025-10-23-191500.md
**Source Spec:** CLAUDE.md (last modified 2025-10-23)
**TODO Reference:** TODO.md (Phase 2 section, lines 3-371)

---

## Executive Summary

**Current State:**
- Phase 1: ‚úÖ COMPLETE (caching, scope hierarchy, instrumentation)
- Phase 2: ‚ùå NOT STARTED (reference index, cache v2, sparse graphs)
- Production Status: üö® BLOCKED by 2 critical bugs (100% failure rate)

**Critical Finding:**
Phase 2 performance work CANNOT proceed until production bugs are fixed. Benchmark script fails in both normal and turbo modes, preventing any measurement of current performance or validation of improvements.

**Primary Bottleneck (Confirmed):**
The `references()` function in `dependency-graph.ts` (lines 228-264) performs O(n¬≤ √ó m √ó k) AST traversals. This is the highest-impact optimization target after bugs are fixed.

**Total Work Items:** 17 tasks across 4 priority levels
**Estimated Total Effort:** 12-18 hours (after P0 bugs fixed)
**Expected Improvement:** 10-100x on medium-large files (500+ identifiers)

---

## Priority Classification

- **P0 (IMMEDIATE):** Production-blocking bugs - MUST fix before any other work
- **P1 (HIGH):** Core Phase 2 optimizations - highest ROI performance improvements
- **P2 (MEDIUM):** Testing and validation - ensure correctness and measure gains
- **P3 (LOW):** Nice-to-have improvements and cleanup

---

## IMMEDIATE PRIORITY (P0) - Unblock Production

These bugs block ALL Phase 2 work. No benchmarking, no performance measurement, no validation possible until fixed.

---

### P0-1: Fix Progress Reporting Crash (Bug #1)

**Status:** Not Started
**Effort:** Small (1-5 minutes)
**Dependencies:** None
**Spec Reference:** CLAUDE.md (Development Commands) ‚Ä¢ **Status Reference:** STATUS-2025-10-23-164430.md (Bug #1, lines 23-84)

#### Description
Normal mode crashes with `TypeError: process.stdout.cursorTo is not a function` when stdout is redirected (e.g., piped to `tee` in benchmark script). This affects ALL production scenarios: CI/CD, logging, benchmarking.

**Root Cause:** Missing optional chaining on line 29 of `src/progress.ts`, despite having it on line 28 for a similar API.

**Evidence:** 6 of 6 packages failed in normal mode benchmark with identical error.

#### Acceptance Criteria
- [ ] Add optional chaining to `process.stdout.cursorTo?.(0)` in `src/progress.ts:29`
- [ ] Verify fix with: `./dist/index.mjs openai test-file.js 2>&1 | tee log.txt`
- [ ] Confirm no crash occurs when stdout is redirected
- [ ] Test passes: `npm run test:unit` still passes
- [ ] Benchmark script completes at least one package in normal mode

#### Technical Notes
```typescript
// BEFORE (line 29):
process.stdout.cursorTo(0);

// AFTER:
process.stdout.cursorTo?.(0);
```

Line 28 already has optional chaining for `clearLine?.(0)` - this is just making it consistent.

**Risk:** Zero (strictly additive, backward compatible)

---

### P0-2: Fix Turbo Mode Promise Serialization (Bug #2)

**Status:** Not Started
**Effort:** Small (5-10 minutes)
**Dependencies:** None
**Spec Reference:** CLAUDE.md (Turbo Mode) ‚Ä¢ **Status Reference:** STATUS-2025-10-23-164430.md (Bug #2, lines 87-192)

#### Description
Turbo mode crashes with `BadRequestError: 400 Invalid type` from OpenAI API because `scopeToString()` is async but not awaited. Promise objects are sent to LLM instead of code strings.

**Root Cause:** Line 143 of `visit-all-identifiers.ts` calls async function without await.

**Evidence:** ALL turbo mode executions fail on first batch. Sequential mode works correctly because it awaits on line 90.

#### Acceptance Criteria
- [ ] Extract contexts in parallel with proper await
- [ ] Verify `job.context` is a string, not a Promise
- [ ] Test with: `./dist/index.mjs openai test-file.js --turbo`
- [ ] Confirm first API call succeeds (not 400 error)
- [ ] Unit tests still pass: `npm run test:unit`
- [ ] Benchmark script completes at least one package in turbo mode

#### Technical Notes

**Recommended Fix (Option 2 - maintains parallelization):**
```typescript
// BEFORE (lines 139-144):
const jobs = toProcess.map((scope) => ({
  scope,
  name: scope.node.name,
  context: scopeToString(scope, contextWindowSize)  // Missing await!
}));

// AFTER:
// Extract all contexts in parallel
const contexts = await Promise.all(
  toProcess.map(scope => scopeToString(scope, contextWindowSize))
);

// Build jobs with resolved contexts
const jobs = toProcess.map((scope, i) => ({
  scope,
  name: scope.node.name,
  context: contexts[i]
}));
```

**Why not Option 1?** Using `await` inside the `map` without `Promise.all` would make extractions sequential, defeating the purpose of turbo mode.

**Risk:** Low (isolated change, matches sequential mode pattern)

---

### P0-3: Establish Performance Baseline

**Status:** Not Started
**Effort:** Small (15-30 minutes)
**Dependencies:** P0-1, P0-2
**Spec Reference:** TODO.md (Task 2.4, lines 240-280) ‚Ä¢ **Status Reference:** STATUS-2025-10-23-191500.md (Recommendations section, lines 541-558)

#### Description
Run fixed benchmark script to document current performance before Phase 2 optimizations. This establishes the baseline for measuring improvements.

**Critical:** Cannot proceed with Phase 2 implementation without knowing current bottlenecks and timing.

#### Acceptance Criteria
- [ ] Benchmark script runs successfully on 3-5 packages
- [ ] Document timing for normal mode per package
- [ ] Document timing for turbo mode per package
- [ ] Record dependency graph build times (from instrumentation output)
- [ ] Identify which packages have 100+ identifiers
- [ ] Capture instrumentation output showing Phase 3 (reference checking) timing
- [ ] Save results to `.agent_planning/BASELINE-PERFORMANCE-2025-10-23.md`

#### Technical Notes

**Packages to benchmark:**
- `colors` (small, ~50 identifiers)
- `debug` (small-medium, ~100 identifiers)
- `axios` (medium, ~300 identifiers)
- `commander` (medium-large, ~500 identifiers)
- `vue` (large, 1000+ identifiers)

**Key metrics to capture:**
```
‚Üí Phase 1: Building scope hierarchy... X.XXs
‚Üí Phase 2: Adding scope containment dependencies... X.XXs
‚Üí Phase 3: Checking references... X.XXs  ‚Üê PRIMARY BOTTLENECK
Total: X.XXs
```

**Expected output format:**
```markdown
## Baseline Performance (Pre-Phase 2)

| Package    | Identifiers | Normal Mode | Turbo Mode | Graph Build | Reference Phase |
|------------|-------------|-------------|------------|-------------|-----------------|
| colors     | ~50         | X.Xs        | X.Xs       | X.Xs        | X.Xs            |
| debug      | ~100        | X.Xs        | X.Xs       | X.Xs        | X.Xs            |
| ...
```

---

## HIGH PRIORITY (P1) - Core Phase 2 Optimizations

These are the highest-ROI performance improvements from the original Phase 2 plan.

---

### P1-1: Implement Reference Index Precomputation

**Status:** Not Started
**Effort:** Medium (2-4 hours)
**Dependencies:** P0-3 (baseline established)
**Spec Reference:** TODO.md (Task 2.1, lines 20-132) ‚Ä¢ **Status Reference:** STATUS-2025-10-23-191500.md (Task 2.1, lines 70-157)

#### Description
Replace O(n¬≤ √ó m √ó k) reference checking with O(n √ó m √ó k) + O(1) lookups by building a reference index once. This is THE primary bottleneck according to TODO.md and STATUS report.

**Current bottleneck:**
```typescript
for (const idA of identifiers) {           // O(n)
  for (const idB of identifiers) {         // O(n)
    if (references(idB, idA)) {            // O(refs √ó AST_nodes) üí•
      deps.push(...);
    }
  }
}
```

**Impact:** 10-100x improvement on reference checking phase (which currently dominates build time).

#### Acceptance Criteria
- [ ] Create `buildReferenceIndex()` function in `dependency-graph.ts`
- [ ] Traverse each identifier's references ONCE (not per pair)
- [ ] Build `Map<name, Set<referencedNames>>` structure
- [ ] Store bindings for verification (handle shadowing correctly)
- [ ] Replace O(n¬≤) `references()` calls with O(1) Map lookups
- [ ] Add timing instrumentation for index building
- [ ] Verify correctness: results match old implementation
- [ ] Unit tests pass (existing + new)
- [ ] Benchmark shows 10-100x improvement on reference phase

#### Technical Notes

**Implementation template (from TODO.md lines 62-131):**

```typescript
interface ReferenceIndex {
  // For each identifier name, which other identifier names it references
  nameReferences: Map<string, Set<string>>;
  // For each identifier, its binding (for verification)
  bindings: Map<string, any>;
}

function buildReferenceIndex(
  identifiers: NodePath<Identifier>[]
): ReferenceIndex {
  console.log(`    ‚Üí Precomputing reference index...`);
  const startTime = performance.now();

  const nameReferences = new Map<string, Set<string>>();
  const bindings = new Map<string, any>();

  for (const id of identifiers) {
    const binding = id.scope.getBinding(id.node.name);
    if (!binding) continue;

    bindings.set(id.node.name, binding);
    const referenced = new Set<string>();

    // Traverse ONCE per identifier (not per pair!)
    for (const refPath of binding.referencePaths) {
      refPath.traverse({
        Identifier(path) {
          const refBinding = path.scope.getBinding(path.node.name);
          if (refBinding) {
            referenced.add(path.node.name);
          }
        }
      });
    }

    nameReferences.set(id.node.name, referenced);
  }

  const elapsed = ((performance.now() - startTime) / 1000).toFixed(2);
  console.log(`    ‚Üí Reference index built in ${elapsed}s`);

  return { nameReferences, bindings };
}
```

**Usage in buildDependencyGraph:**
```typescript
// Build reference index
const refIndex = buildReferenceIndex(identifiers);

// Use O(1) lookups instead of O(refs √ó AST_nodes)
for (const idA of identifiers) {
  for (const idB of identifiers) {
    if (idA === idB) continue;

    const idBRefs = refIndex.nameReferences.get(idB.node.name);
    if (idBRefs?.has(idA.node.name)) {
      // Verify bindings match
      const idABinding = refIndex.bindings.get(idA.node.name);
      const idBBinding = refIndex.bindings.get(idB.node.name);
      if (idABinding && idBBinding) {
        deps.push({ from: idA, to: idB, reason: 'reference' });
      }
    }
  }
}
```

**Critical:** Must verify bindings to handle shadowed variables correctly (same name, different scopes).

**Expected Performance (from TODO.md):**
- Small files (100 ids): 2-5x faster
- Medium files (500 ids): 10-20x faster
- Large files (1000+ ids): 20-100x faster

---

### P1-2: Update Cache Format to v2

**Status:** Not Started
**Effort:** Medium (1-2 hours)
**Dependencies:** P1-1 (reference index implemented)
**Spec Reference:** TODO.md (Task 2.2, lines 135-180) ‚Ä¢ **Status Reference:** STATUS-2025-10-23-191500.md (Task 2.2, lines 161-202)

#### Description
Upgrade cache format from v1.0 to v2.0 to include precomputed indices (scope hierarchy + reference index). This makes cache hits even faster by skipping index building.

**Current state:** Cache v1.0 only stores dependencies, requires rebuilding indices on every run.

**Impact:** Medium (faster cold starts when cache misses)

#### Acceptance Criteria
- [ ] Bump `CACHE_VERSION` from `"1.0"` to `"2.0"` in `dependency-cache.ts:10`
- [ ] Add `scopeHierarchy` field to `CacheEntry` interface
- [ ] Add `referenceIndex` field to `CacheEntry` interface
- [ ] Serialize Map objects to JSON-compatible format `[key, value[]][]`
- [ ] Deserialize Maps when loading cache
- [ ] Invalidate v1 caches (version check triggers rebuild)
- [ ] Test cache save/load round-trip
- [ ] Verify cache hit skips index building (timing confirms)

#### Technical Notes

**New cache format (from TODO.md lines 163-179):**

```typescript
interface CacheEntryV2 {
  fileHash: string;
  identifierCount: number;
  identifierNames: string[];
  dependencies: SerializedDependency[];

  // NEW: Precomputed indices
  scopeHierarchy: [number, number[]][]; // [outerIdx, [innerIdx...]]
  referenceIndex: {
    nameReferences: [string, string[]][]; // [name, [referencedNames...]]
    // Note: bindings can't be serialized, must rebuild on load
  };

  timestamp: number;
  version: string; // "2.0"
}
```

**Serialization strategy:**
- `Map<NodePath, Set<NodePath>>` ‚Üí `[number, number[]][]` (use index mapping)
- `Map<string, Set<string>>` ‚Üí `[string, string[]][]`

**Migration:** Old v1 caches will fail version check and be rebuilt automatically.

---

### P1-3: Re-evaluate Sparse Graph vs Dependency Modes

**Status:** Not Started
**Effort:** Small (30-60 minutes)
**Dependencies:** P0-3 (baseline with dependency modes tested)
**Spec Reference:** TODO.md (Task 2.3, lines 183-237) ‚Ä¢ **Status Reference:** STATUS-2025-10-23-191500.md (Sparse Graph section, lines 215-241)

#### Description
Determine if sparse graph construction (Task 2.3 from TODO.md) is still needed given that dependency modes (strict/balanced/relaxed) were implemented as an alternative.

**Context:** TODO.md planned sparse graphs, but the codebase instead implemented user-configurable dependency modes. This achieves similar goals (reducing graph density) through a different approach.

**Decision Point:** Benchmark dependency modes performance, then decide whether to:
1. SKIP sparse graphs (if modes provide sufficient performance)
2. IMPLEMENT sparse graphs (if modes are insufficient)
3. COMBINE both (orthogonal features: `--dependency-mode balanced --sparse`)

#### Acceptance Criteria
- [ ] Run benchmarks with `--dependency-mode strict` (full graph)
- [ ] Run benchmarks with `--dependency-mode balanced` (direct edges only)
- [ ] Run benchmarks with `--dependency-mode relaxed` (no scope containment)
- [ ] Compare graph size (edge count) for each mode
- [ ] Compare build times for each mode
- [ ] Measure impact on rename quality (if possible)
- [ ] Document findings in `.agent_planning/DEPENDENCY-MODES-EVALUATION.md`
- [ ] Update TODO.md with decision (skip/implement/combine)

#### Technical Notes

**Dependency modes (already implemented):**
- `strict`: Full scope containment + references (original behavior)
- `balanced`: Direct parent-child only + references (fewer edges)
- `relaxed`: References only, skip scope containment (fastest)

**Sparse graphs (from TODO.md):**
- Group identifiers by scope depth
- Only check containment between adjacent levels
- Auto-select for files with >200 identifiers

**Questions to answer:**
1. Does `balanced` mode provide similar speedup to sparse graphs?
2. Is there value in combining both approaches?
3. Does reducing graph density hurt rename quality?

**Expected Outcome:** If balanced mode provides 2-5x speedup with acceptable quality, sparse graphs can be skipped. Otherwise, implement as orthogonal feature.

---

## MEDIUM PRIORITY (P2) - Testing & Validation

These tasks ensure correctness and provide measurement infrastructure.

---

### P2-1: Create Dependency Graph Unit Tests

**Status:** Not Started
**Effort:** Medium (1-2 hours)
**Dependencies:** P1-1 (reference index implemented)
**Spec Reference:** TODO.md (Task 2.1 acceptance criteria) ‚Ä¢ **Status Reference:** STATUS-2025-10-23-191500.md (Test Coverage Analysis, lines 269-300)

#### Description
Create comprehensive unit tests for dependency graph construction, especially the new reference index feature. Current test coverage is indirect (turbo-mode.test.ts exercises graph via integration).

**Critical Gap:** No dedicated tests for `buildReferenceIndex()` or reference detection logic.

#### Acceptance Criteria
- [ ] Create `src/plugins/local-llm-rename/dependency-graph.test.ts`
- [ ] Test `buildReferenceIndex()` with basic references
- [ ] Test with shadowed variables (same name, different bindings)
- [ ] Test with nested scopes
- [ ] Test with circular references
- [ ] Compare new implementation results with old `references()` behavior
- [ ] Test cache serialization/deserialization
- [ ] Test scope hierarchy building
- [ ] All tests pass in `npm run test:unit`

#### Technical Notes

**Test cases to cover:**

1. **Basic reference detection:**
```typescript
test('detects simple variable reference', () => {
  const code = `
    const a = 1;
    const b = a + 2;
  `;
  // b should reference a
});
```

2. **Shadowed variables:**
```typescript
test('handles shadowing correctly', () => {
  const code = `
    const x = 1;
    function foo() {
      const x = 2;  // Different binding
      return x;
    }
  `;
  // Inner x should NOT reference outer x
});
```

3. **Nested scopes:**
```typescript
test('handles nested scope references', () => {
  const code = `
    function outer() {
      const a = 1;
      function inner() {
        return a;  // References outer a
      }
    }
  `;
  // inner function references should be detected
});
```

4. **Cache round-trip:**
```typescript
test('cache v2 serialization preserves reference index', async () => {
  const deps = buildDependencyGraph(code, identifiers);
  await saveDependencyCache(code, identifiers, deps);
  const cached = await getCachedDependencies(code, identifiers);
  expect(cached).toEqual(deps);
});
```

---

### P2-2: Add Turbo Mode Integration Tests

**Status:** Not Started
**Effort:** Small (30-60 minutes)
**Dependencies:** P0-2 (Bug #2 fixed)
**Spec Reference:** CLAUDE.md (Test Patterns) ‚Ä¢ **Status Reference:** STATUS-2025-10-23-164430.md (Test Coverage Gaps, lines 227-247)

#### Description
Current turbo mode tests use mock visitors that ignore `surroundingCode` parameter. This allowed Bug #2 to pass tests. Add integration tests that verify real provider plugins work correctly in turbo mode.

**Gap:** No test that actually passes `surroundingCode` to a visitor, so Promise bug was undetected.

#### Acceptance Criteria
- [ ] Create test that uses real OpenAI plugin structure (mocked HTTP)
- [ ] Verify `surroundingCode` parameter is a string, not Promise
- [ ] Test batch processing with multiple identifiers
- [ ] Test concurrency limiting
- [ ] Verify parallel API calls work correctly
- [ ] Add test to `src/plugins/openai/openai-turbo.test.ts`
- [ ] Consider similar test for Gemini

#### Technical Notes

**Test structure:**
```typescript
test('turbo mode passes string context to visitor', async () => {
  const code = `const a = 1; const b = a + 2;`;

  const visitor = async (name: string, surroundingCode: string) => {
    // CRITICAL: Verify it's a string, not a Promise
    expect(typeof surroundingCode).toBe('string');
    expect(surroundingCode).toContain('const');
    return name + '_renamed';
  };

  const result = await visitAllIdentifiers(
    code,
    visitor,
    { turbo: true, batchSize: 10 }
  );

  expect(result).toBeTruthy();
});
```

**Why this catches Bug #2:**
If `surroundingCode` is a Promise, `typeof` would be 'object' and `toContain` would fail (Promises don't have string methods).

---

### P2-3: Add Redirected Stdout E2E Test

**Status:** Not Started
**Effort:** Small (15-30 minutes)
**Dependencies:** P0-1 (Bug #1 fixed)
**Spec Reference:** CLAUDE.md (Test Patterns) ‚Ä¢ **Status Reference:** STATUS-2025-10-23-164430.md (Test Coverage Gaps, lines 229-232)

#### Description
Add E2E test that verifies the CLI works correctly when stdout is redirected, as happens in production (CI, benchmarking, logging).

**Gap:** No test exercises redirected stdout, which is how Bug #1 manifested.

#### Acceptance Criteria
- [ ] Create E2E test that spawns CLI process with redirected stdout
- [ ] Verify process exits successfully (code 0)
- [ ] Verify output is captured correctly
- [ ] Test both normal and turbo modes
- [ ] Add to `*.e2etest.ts` suite

#### Technical Notes

**Test approach:**
```typescript
test('CLI works with redirected stdout', async () => {
  const { spawn } = await import('child_process');

  const proc = spawn('./dist/index.mjs', [
    'openai',
    'test-samples/small.js'
  ], {
    stdio: ['ignore', 'pipe', 'pipe']  // Redirect stdout
  });

  let output = '';
  proc.stdout.on('data', (chunk) => {
    output += chunk.toString();
  });

  const exitCode = await new Promise((resolve) => {
    proc.on('close', resolve);
  });

  expect(exitCode).toBe(0);
  expect(output).toContain('Processing:');
});
```

---

### P2-4: Create Performance Benchmark Suite

**Status:** Not Started
**Effort:** Medium (2-3 hours)
**Dependencies:** P1-1, P1-2 (Phase 2 optimizations complete)
**Spec Reference:** TODO.md (Task 2.4, lines 240-280) ‚Ä¢ **Status Reference:** STATUS-2025-10-23-191500.md (Task 2.4, lines 247-265)

#### Description
Create formal benchmark infrastructure to measure Phase 2 improvements objectively. Current benchmark-script.sh is ad-hoc; this creates a proper benchmarking suite.

**Purpose:** Document performance gains from Phase 2 work.

#### Acceptance Criteria
- [ ] Create `benchmark/` directory
- [ ] Add `benchmark/dependency-graph-benchmark.ts` script
- [ ] Generate test files with 100, 500, 1000 identifiers
- [ ] Measure build time with cache miss
- [ ] Measure build time with cache hit
- [ ] Compare Phase 1 vs Phase 2 performance
- [ ] Output results in markdown table format
- [ ] Add `npm run benchmark` script to package.json
- [ ] Document results in `.agent_planning/PHASE-2-PERFORMANCE-RESULTS.md`

#### Technical Notes

**Benchmark output format (from TODO.md lines 258-279):**

```markdown
## Dependency Graph Performance Benchmark

### Test file: 100 identifiers
- Phase 1 (cache miss): 2.3s
- Phase 1 (cache hit):  0.001s
- Phase 2 (cache miss): 0.8s
- Phase 2 (cache hit):  0.001s
- **Improvement: 2.9x**

### Test file: 500 identifiers
- Phase 1 (cache miss): 45.2s
- Phase 1 (cache hit):  0.002s
- Phase 2 (cache miss): 3.1s
- Phase 2 (cache hit):  0.002s
- **Improvement: 14.6x**

### Test file: 1000 identifiers
- Phase 1 (cache miss): 180.5s
- Phase 1 (cache hit):  0.003s
- Phase 2 (cache miss): 8.2s
- Phase 2 (cache hit):  0.003s
- **Improvement: 22.0x**
```

**Test file generation:**
```bash
node scripts/generate-test-file.js 100   > test-samples/bench-100.js
node scripts/generate-test-file.js 500   > test-samples/bench-500.js
node scripts/generate-test-file.js 1000  > test-samples/bench-1000.js
```

---

### P2-5: Validate Phase 2 Correctness

**Status:** Not Started
**Effort:** Small (30-60 minutes)
**Dependencies:** P1-1, P1-2 (Phase 2 features implemented)
**Spec Reference:** TODO.md (Success Criteria, lines 297-307)

#### Description
Verify that Phase 2 optimizations produce identical results to Phase 1. The reference index must match the old `references()` behavior exactly.

**Critical:** Optimizations should not change output, only speed.

#### Acceptance Criteria
- [ ] Run same input file through Phase 1 and Phase 2
- [ ] Compare dependency graphs (should be identical)
- [ ] Compare final renamed output (should be identical)
- [ ] Test with 10+ different files
- [ ] Test with files containing shadowed variables
- [ ] Test with deeply nested scopes
- [ ] Document any discrepancies (there should be none)
- [ ] All existing integration tests pass unchanged

#### Technical Notes

**Validation approach:**

1. Temporarily keep old `references()` function
2. Build graph with old method
3. Build graph with new method (reference index)
4. Deep compare results
5. If identical, remove old code
6. If different, debug and fix

**Test files should include:**
- Simple flat scope
- Nested functions
- Class methods
- Arrow functions
- Destructuring
- Shadowed variables
- Module imports/exports

---

## LOW PRIORITY (P3) - Nice-to-Have Improvements

These tasks improve developer experience and code quality but are not critical for Phase 2 success.

---

### P3-1: Remove Async from scopeToString (Technical Debt)

**Status:** Not Started
**Effort:** Small (20-30 minutes)
**Dependencies:** P0-2 (Bug #2 fixed)
**Spec Reference:** None (technical debt) ‚Ä¢ **Status Reference:** STATUS-2025-10-23-164430.md (Related Technical Debt, lines 196-225)

#### Description
The `scopeToString` function is marked `async` but performs no async operations. This adds unnecessary promise wrapping and contributed to Bug #2 (easy to forget await for async functions).

**Question:** Is there a valid reason it's async, or is this technical debt?

#### Acceptance Criteria
- [ ] Review all call sites to understand if async is needed
- [ ] If not needed: Remove `async` keyword from function signature
- [ ] If not needed: Remove `await` from all call sites
- [ ] If needed: Document WHY it's async in a comment
- [ ] All tests pass after changes
- [ ] TypeScript compiles without errors

#### Technical Notes

**Current signature (line 207):**
```typescript
async function scopeToString(
  path: NodePath<Identifier>,
  contextWindowSize: number
) {
  // Contains no await statements!
}
```

**If removing async:**
```typescript
function scopeToString(
  path: NodePath<Identifier>,
  contextWindowSize: number
): string {
  // Implementation unchanged
}
```

**Call sites to update:**
- Line 90 (sequential mode): `const surroundingCode = scopeToString(...);`
- Line 143 (turbo mode): `context: scopeToString(...)` (no longer needs await)

**Risk:** Medium (breaking change if external code depends on it)

**Alternative:** Keep it async and document the reason. This is safer if there's hidden coupling.

---

### P3-2: Refactor Progress Reporting (Better Design)

**Status:** Not Started
**Effort:** Medium (1-2 hours)
**Dependencies:** P0-1 (Bug #1 fixed)
**Spec Reference:** None (technical debt) ‚Ä¢ **Status Reference:** STATUS-2025-10-23-164430.md (Progress Reporting Design, lines 248-287)

#### Description
Current `progress.ts` directly accesses `process.stdout`, making it untestable and fragile. Refactor to use dependency injection with a ProgressReporter interface.

**Benefits:**
- Testable (can inject mock reporter)
- Respects TTY detection
- Extensible (custom reporters)
- Follows SOLID principles

#### Acceptance Criteria
- [ ] Create `ProgressReporter` interface
- [ ] Implement `TTYProgressReporter` (current behavior)
- [ ] Implement `LogProgressReporter` (for non-TTY)
- [ ] Auto-detect TTY and select appropriate reporter
- [ ] Update all call sites to use new API
- [ ] Add unit tests for reporters
- [ ] Verify works in both TTY and redirected stdout
- [ ] All integration tests still pass

#### Technical Notes

**Interface design (from STATUS-2025-10-23-164430.md):**

```typescript
interface ProgressReporter {
  update(percentage: number): void;
}

class TTYProgressReporter implements ProgressReporter {
  update(percentage: number) {
    if (process.stdout.isTTY) {
      process.stdout.clearLine?.(0);
      process.stdout.cursorTo?.(0);
      process.stdout.write(`Processing: ${Math.round(percentage * 100)}%`);
    }
  }
}

class LogProgressReporter implements ProgressReporter {
  private lastReported = -1;

  update(percentage: number) {
    const percentInt = Math.round(percentage * 100);
    // Only log on 10% increments
    if (percentInt >= this.lastReported + 10) {
      console.log(`Processing: ${percentInt}%`);
      this.lastReported = percentInt;
    }
  }
}
```

**Auto-selection:**
```typescript
export function createProgressReporter(): ProgressReporter {
  return process.stdout.isTTY
    ? new TTYProgressReporter()
    : new LogProgressReporter();
}
```

---

### P3-3: Add Cache Management Commands

**Status:** Not Started
**Effort:** Small (30-60 minutes)
**Dependencies:** P1-2 (Cache v2 implemented)
**Spec Reference:** TODO.md (Tooling section, lines 360-364)

#### Description
Add CLI commands to manage the dependency graph cache: view stats, clear cache, inspect entries.

**Use cases:**
- Debugging cache issues
- Clearing cache after version upgrade
- Understanding cache hit rates

#### Acceptance Criteria
- [ ] Add `--clear-cache` flag to all commands
- [ ] Add `humanify cache-info` command showing:
  - Cache directory size
  - Number of entries
  - Oldest/newest entry timestamps
  - Cache version distribution (v1 vs v2)
- [ ] Add `humanify cache-clear` command to wipe cache
- [ ] Update CLI help text
- [ ] Add to CLAUDE.md documentation

#### Technical Notes

**Commands to add:**

```bash
# Clear cache before run
humanify openai input.js --clear-cache

# View cache statistics
humanify cache-info

# Output:
# Cache location: .humanify-cache/dependencies
# Total entries: 42
# Total size: 1.2 MB
# Cache v1: 15 entries
# Cache v2: 27 entries
# Oldest entry: 2025-10-20 (3 days ago)
# Newest entry: 2025-10-23 (today)

# Clear all cache
humanify cache-clear
# Confirm: Delete 42 cache entries? [y/N]
```

---

### P3-4: Add Cache Size Limit and Auto-Cleanup

**Status:** Not Started
**Effort:** Small (1 hour)
**Dependencies:** P1-2 (Cache v2 implemented)
**Spec Reference:** TODO.md (Tooling section, line 364)

#### Description
Implement automatic cleanup of old cache entries to prevent unbounded growth. Set size limit (e.g., 100 MB or 1000 entries) and LRU eviction.

#### Acceptance Criteria
- [ ] Add `CACHE_MAX_ENTRIES` constant (default: 1000)
- [ ] Add `CACHE_MAX_SIZE_MB` constant (default: 100)
- [ ] Check limits on cache save
- [ ] Evict oldest entries (by timestamp) when limit exceeded
- [ ] Log when cleanup occurs
- [ ] Add `--cache-max-entries` CLI flag to override default
- [ ] Test with large number of files

#### Technical Notes

**Cleanup logic:**
```typescript
async function evictOldCacheEntries() {
  const entries = await fs.readdir(CACHE_DIR);
  const stats = await Promise.all(
    entries.map(async (file) => ({
      file,
      mtime: (await fs.stat(path.join(CACHE_DIR, file))).mtime
    }))
  );

  // Sort by modification time (oldest first)
  stats.sort((a, b) => a.mtime.getTime() - b.mtime.getTime());

  // Remove oldest entries until under limit
  while (stats.length > CACHE_MAX_ENTRIES) {
    const oldest = stats.shift()!;
    await fs.unlink(path.join(CACHE_DIR, oldest.file));
    console.log(`    ‚Üí Evicted old cache entry: ${oldest.file}`);
  }
}
```

---

### P3-5: Document Phase 2 Results and Update TODO.md

**Status:** Not Started
**Effort:** Small (30-60 minutes)
**Dependencies:** All P1 and P2 tasks complete
**Spec Reference:** TODO.md (Future Enhancements, lines 342-349)

#### Description
Update project documentation to reflect Phase 2 completion, mark tasks as done in TODO.md, and document performance improvements.

#### Acceptance Criteria
- [ ] Update TODO.md Phase 2 status from "Not started" to "Complete"
- [ ] Check off all completed tasks in TODO.md
- [ ] Document actual performance improvements (vs. estimates)
- [ ] Update CLAUDE.md with Phase 2 features if needed
- [ ] Create `.agent_planning/PHASE-2-RETROSPECTIVE.md` documenting:
  - What went well
  - What didn't work as expected
  - Lessons learned
  - Actual vs estimated effort
- [ ] Archive old planning files to `.agent_planning/archive/`

#### Technical Notes

**Retrospective should answer:**
1. Did we achieve 10-100x improvement as expected?
2. Which optimizations had highest impact?
3. Were there unexpected challenges?
4. What would we do differently?
5. Is Phase 3 needed or is performance acceptable?

---

### P3-6: Clean Up Obsolete Planning Files

**Status:** Not Started
**Effort:** Small (15-30 minutes)
**Dependencies:** P3-5 (documentation updated)
**Spec Reference:** System prompt (File Management section)

#### Description
Archive obsolete planning files to prevent confusion. Keep only the 4 most recent of each prefix (PLAN, STATUS, TODO, SPRINT).

**Current state:** 16 planning files, some potentially outdated or contradictory.

#### Acceptance Criteria
- [ ] Create `.agent_planning/archive/` directory
- [ ] Review all planning files for relevance
- [ ] Keep 4 most recent PLAN-*.md files
- [ ] Keep 4 most recent STATUS-*.md files
- [ ] Keep 4 most recent TODO-*.md files
- [ ] Archive older files with `.archived` suffix
- [ ] Archive analysis docs no longer relevant:
  - `parallelization-analysis.md` (superseded by turbo mode)
  - `feasibility-analysis.md` (if work is done)
  - `optimal-ordering-analysis.md` (if work is done)
- [ ] Keep active docs:
  - `dependency-graph-optimization.md` (Phase 2 plan)
  - `instrumentation-guide.md` (useful reference)
  - `batch-optimization-summary.md` (if still relevant)

#### Technical Notes

**Files to review:**
```
batch-optimization-summary.md
dependency-graph-optimization.md
feasibility-analysis.md
instrumentation-guide.md
optimal-ordering-analysis.md
ordering-vs-parallelization.md
PARALLELIZATION_SUMMARY.md
parallelization-analysis.md
parallelization-plan.md
PLAN-2025-10-23-164727.md
PLANNING-SUMMARY-2025-10-23-164727.md
STATUS-2025-10-23-164430.md
STATUS-2025-10-23-191500.md
TODO-2025-10-23-164727.md
UNIFIED_IMPLEMENTATION_PLAN.md
```

**Retention policy (from system prompt):**
- Keep exactly 4 most recent PLAN-*.md
- Keep exactly 4 most recent STATUS-*.md (read-only)
- Archive others to prevent confusion

---

## Dependency Graph

```
P0-1 (Fix Bug #1)
  ‚Üì
P0-3 (Establish Baseline) ‚Üê--- P0-2 (Fix Bug #2)
  ‚Üì
P1-1 (Reference Index) ----‚Üí P1-2 (Cache v2)
  ‚Üì                            ‚Üì
P2-1 (Unit Tests)         P2-4 (Benchmark Suite)
  ‚Üì                            ‚Üì
P2-5 (Validate Correctness) ‚Üê--‚îò
  ‚Üì
P3-5 (Documentation)
  ‚Üì
P3-6 (Cleanup)

P0-3 ‚Üí P1-3 (Evaluate Modes)

P0-1 ‚Üí P2-3 (E2E Test)
P0-2 ‚Üí P2-2 (Integration Test)
P0-2 ‚Üí P3-1 (Remove async)

P0-1 ‚Üí P3-2 (Refactor Progress)

P1-2 ‚Üí P3-3 (Cache Commands)
P1-2 ‚Üí P3-4 (Cache Limits)
```

---

## Recommended Sprint Planning

### Sprint 1: Unblock Production (1 day)
**Goal:** Fix critical bugs and establish baseline

- P0-1: Fix progress reporting crash
- P0-2: Fix turbo mode Promise bug
- P0-3: Establish performance baseline
- P2-2: Add turbo integration tests
- P2-3: Add redirected stdout E2E test

**Exit Criteria:** Benchmark script runs successfully, baseline documented

---

### Sprint 2: Core Optimizations (3-5 days)
**Goal:** Implement primary Phase 2 optimizations

- P1-1: Implement reference index
- P1-2: Update cache to v2
- P1-3: Evaluate dependency modes
- P2-1: Create dependency graph unit tests
- P2-5: Validate correctness

**Exit Criteria:** Reference index working, cache v2 tested, correctness verified

---

### Sprint 3: Measurement & Polish (2-3 days)
**Goal:** Measure improvements and clean up

- P2-4: Create benchmark suite
- P3-5: Document Phase 2 results
- P3-6: Clean up planning files
- Optional: P3-1, P3-2, P3-3, P3-4 (technical debt)

**Exit Criteria:** Performance gains documented, TODO.md updated, ready for Phase 3 decision

---

## Risk Assessment

### High Risk Items

**P1-1 (Reference Index):**
- **Risk:** Incorrect handling of shadowed variables
- **Mitigation:** Comprehensive unit tests, compare with old implementation
- **Likelihood:** Medium
- **Impact:** High (incorrect output)

**P1-2 (Cache v2):**
- **Risk:** Serialization bugs, cache corruption
- **Mitigation:** Thorough round-trip testing, version validation
- **Likelihood:** Low
- **Impact:** Medium (degraded performance, no data loss)

### Medium Risk Items

**P0-2 (Bug #2 Fix):**
- **Risk:** Breaking parallelization if not careful
- **Mitigation:** Use Option 2 (parallel await), test thoroughly
- **Likelihood:** Low
- **Impact:** Medium (performance regression)

**P2-5 (Correctness Validation):**
- **Risk:** Discovering reference index has subtle bugs
- **Mitigation:** Test extensively before declaring complete
- **Likelihood:** Medium
- **Impact:** High (requires rework of P1-1)

### Low Risk Items

All P0-1, P2-*, P3-* tasks have low risk (additive changes, good test coverage).

---

## Success Metrics

Phase 2 is complete when:

- ‚úÖ Both production bugs fixed (100% benchmark success rate)
- ‚úÖ Performance baseline documented
- ‚úÖ Reference index implemented and tested
- ‚úÖ Cache v2 working with serialization
- ‚úÖ All unit tests pass
- ‚úÖ All integration tests pass
- ‚úÖ Correctness validation shows identical output
- ‚úÖ Benchmarks show 10-100x improvement on medium-large files
- ‚úÖ Cache hits remain ~0ms (unchanged from Phase 1)
- ‚úÖ Documentation updated

**Target Performance (from TODO.md):**

| File Size | Phase 1 | Phase 2 | Improvement |
|-----------|---------|---------|-------------|
| 100 ids   | 2-5s    | 0.5-2s  | 2-5x        |
| 500 ids   | 30-120s | 2-10s   | 10-20x      |
| 1000 ids  | 5-20min | 10-60s  | 20-100x     |

**Actual results will be measured in P2-4 (Benchmark Suite).**

---

## Appendix: File Inventory

### Files to Modify

**P0 Bugs:**
- `src/progress.ts` (Bug #1)
- `src/plugins/local-llm-rename/visit-all-identifiers.ts` (Bug #2)

**P1 Optimizations:**
- `src/plugins/local-llm-rename/dependency-graph.ts` (reference index)
- `src/plugins/local-llm-rename/dependency-cache.ts` (cache v2)

**P2 Tests:**
- `src/plugins/local-llm-rename/dependency-graph.test.ts` (new)
- `src/plugins/openai/openai-turbo.test.ts` (augment)
- `test/e2e-redirected-stdout.e2etest.ts` (new)

**P3 Improvements:**
- `src/progress.ts` (refactor)
- `src/commands/*.ts` (cache commands)

### Files to Create

**Benchmarking:**
- `benchmark/dependency-graph-benchmark.ts`
- `test-samples/bench-100.js`
- `test-samples/bench-500.js`
- `test-samples/bench-1000.js`

**Documentation:**
- `.agent_planning/BASELINE-PERFORMANCE-2025-10-23.md`
- `.agent_planning/DEPENDENCY-MODES-EVALUATION.md`
- `.agent_planning/PHASE-2-PERFORMANCE-RESULTS.md`
- `.agent_planning/PHASE-2-RETROSPECTIVE.md`

---

## Blockers and Questions

### Critical Blockers (Must Resolve Before P1)

1. **Are both bugs actually present?**
   - STATUS report documents them, but should verify in current code
   - Action: Review `src/progress.ts:29` and `visit-all-identifiers.ts:143`

2. **Can benchmarks run after bug fixes?**
   - Need working benchmark script to establish baseline
   - Action: Test benchmark-script.sh after applying fixes

### Questions for User

1. **Should sparse graphs (Task 2.3) be implemented or skipped?**
   - Depends on dependency modes performance (P1-3 will answer)
   - Decision point after P0-3 (baseline) completes

2. **What is the cache retention policy?**
   - Should cache be committed to repo or gitignored?
   - Affects team workflow (shared cache vs individual)

3. **Is Phase 3 (advanced optimizations) still desired?**
   - Worker threads or Rust native module
   - Decision point after Phase 2 results measured
   - May not be needed if Phase 2 provides sufficient speedup

---

**END OF BACKLOG**
